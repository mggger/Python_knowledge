{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling\n",
    "\n",
    "    所有像Dask Array，Dask dataframe和Dask bag这样的大规模Dask集合以及delayed, futures这些API都会生成任务图，其中图中的每个节点都是普通的Python函数，节点之间的边是普通的Python由一个任务创建的对象作为ouptuts并用作另一个任务的输入。 Dask生成这些任务图后，需要在并行硬件上执行它们。这是任务调度器的工作。存在不同的任务调度程序。每个将消耗一个任务图并计算相同的结果，但具有不同的性能特征。\n",
    "![task_graph](collections-schedulers.png)\n",
    "***\n",
    "**Dask的调度程序：**\n",
    "+ Single machine scheduler:    \n",
    "    1. synchronous\n",
    "    2. multiprocessing \n",
    "    3. threaded     \n",
    "+ Distributed scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单机任务调度\n",
    "\n",
    "**synchronous**: 适用于程序调试过程(默认)     \n",
    "**multiprocessing**: 将数据移动到远程进程并返回会导致性能损失，特别是在进程之间传输的数据很大时。当工作流程相对线性时，多处理调度程序是一个很好的选择。     \n",
    "**thread**: 因为*GIL(全局解释锁)*的存在，有些计算密集的程序无法实现并行\n",
    "***\n",
    "#### 快速上手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 2.18 s, total: 13.4 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask.delayed import delayed\n",
    "import pandas as pd \n",
    "import dask\n",
    "dask.config.set(scheduler='synchronous')\n",
    "\n",
    "files = ['data1/1.csv',\n",
    "         'data1/2.csv',\n",
    "         'data1/3.csv',\n",
    "         'data1/4.csv']\n",
    "tasks = []\n",
    "\n",
    "for file in files:\n",
    "    df = delayed(pd.read_csv)(file)\n",
    "    tasks.append(df['Key'].count())\n",
    "\n",
    "result = delayed(sum)(tasks)\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 ms, sys: 51.3 ms, total: 82.3 ms\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dask.config.set(scheduler='processes')  # overwrite default with multiprocessing scheduler\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 3.55 s, total: 20.3 s\n",
      "Wall time: 7.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dask.config.set(scheduler='threads')   # overwrite default with threadingpool scheduler\n",
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分布式任务调度\n",
    "#### 快速上手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dashboard简介**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "x = da.random.random((10000, 10000, 10), chunks=(1000, 1000, 5))\n",
    "y = da.random.random((10000, 10000, 10), chunks=(1000, 1000, 5))\n",
    "z = (da.arcsin(x) + da.arccos(y)).sum(axis=(1,2))\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在集群上启动运算**     \n",
    "通过map/submit方法在集群上启动运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "A = client.map(square, range(1, 10))\n",
    "total = client.submit(sum, A)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**访问future对象的运算结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.gather(A)\n",
    "#client.gather(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**节点之间传递数据集**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data1/1.csv').head()\n",
    "client.publish_dataset(df1=df)   # save value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_datasets()            #获取dataset列表\n",
    "df = client.get_dataset('df1')    #获取dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "dask推荐的流式处理方式是使用python标准库的Queue。\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
